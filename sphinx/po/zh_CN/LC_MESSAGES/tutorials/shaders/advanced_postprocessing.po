# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2014-present Juan Linietsky, Ariel Manzur and the Godot community (CC BY 3.0)
# This file is distributed under the same license as the Godot Engine package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Godot Engine 4.2\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2024-02-27 19:04+0100\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: zh_CN\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

msgid "Advanced post-processing"
msgstr "高级后期处理"

msgid "Introduction"
msgstr "前言"

msgid ""
"This tutorial describes an advanced method for post-processing in Godot. In "
"particular, it will explain how to write a post-processing shader that uses "
"the depth buffer. You should already be familiar with post-processing "
"generally and, in particular, with the methods outlined in the :ref:`custom "
"post-processing tutorial <doc_custom_postprocessing>`."
msgstr ""
"本教程描述了一种在 Godot 中进行后期处理的高级方法。值得注意的是，它将解释如何"
"编写使用深度缓冲区的后期处理着色器。你应该已经熟悉后期处理，特别是使用\\ :"
"ref:`自定义后期处理教程 <doc_custom_postprocessing>`\\ 中介绍的方法。"

#, fuzzy
msgid ""
"In the previous post-processing tutorial, we rendered the scene to a :ref:"
"`Viewport <class_Viewport>` and then rendered the Viewport in a :ref:"
"`SubViewportContainer <class_SubViewportContainer>` to the main scene. One "
"limitation of this method is that we could not access the depth buffer "
"because the depth buffer is only available in shaders and Viewports do not "
"maintain depth information."
msgstr ""
"在前面的后期处理教程中，我们将场景渲染到了 :ref:`Viewport <class_Viewport>` "
"中，然后将这个 Viewport 在 :ref:`ViewportContainer "
"<class_ViewportContainer>` 中渲染到主场景。这个方法存在一个局限，我们无法访问"
"深度缓冲区，因为深度缓冲区只在空间着色器中可用，Viewport 并不维护深度信息。"

msgid "Full screen quad"
msgstr "全屏四边形"

msgid ""
"In the :ref:`custom post-processing tutorial <doc_custom_postprocessing>`, "
"we covered how to use a Viewport to make custom post-processing effects. "
"There are two main drawbacks of using a Viewport:"
msgstr ""
"在\\ :ref:`自定义后期处理教程<doc_custom_postprocessing>`\\ 中，我们介绍了如"
"何使用 Viewport 来制作自定义的后期处理特效。使用 Viewport 有两个主要的缺点："

msgid "The depth buffer cannot be accessed"
msgstr "无法访问深度缓冲区"

msgid "The effect of the post-processing shader is not visible in the editor"
msgstr "在编辑器中看不到后期处理着色器的效果"

#, fuzzy
msgid ""
"To get around the limitation on using the depth buffer, use a :ref:"
"`MeshInstance3D <class_MeshInstance3D>` with a :ref:`QuadMesh "
"<class_QuadMesh>` primitive. This allows us to use a shader and to access "
"the depth texture of the scene. Next, use a vertex shader to make the quad "
"cover the screen at all times so that the post-processing effect will be "
"applied at all times, including in the editor."
msgstr ""
"要解决使用深度缓冲区的限制，请使用 :ref:`MeshInstance <class_MeshInstance>` "
"并设置 :ref:`QuadMesh <class_QuadMesh>` 图元。这样我们就可以使用空间着色器，"
"并且可以访问该场景的深度纹理。接下来，请使用顶点着色器让这个四边形始终覆盖屏"
"幕，以便始终应用后期处理效果，包括在编辑器中。"

#, fuzzy
msgid ""
"First, create a new MeshInstance3D and set its mesh to a QuadMesh. This "
"creates a quad centered at position ``(0, 0, 0)`` with a width and height of "
"``1``. Set the width and height to ``2`` and enable **Flip Faces**. Right "
"now, the quad occupies a position in world space at the origin. However, we "
"want it to move with the camera so that it always covers the entire screen. "
"To do this, we will bypass the coordinate transforms that translate the "
"vertex positions through the difference coordinate spaces and treat the "
"vertices as if they were already in clip space."
msgstr ""
"首先，新建一个 MeshInstance，并将其网格设置为 QuadMesh。这将创建一个以坐标 "
"``(0, 0, 0)`` 为中心的四边形，宽度和高度均为 ``1``\\ 。请将其宽度和高度设置"
"为 ``2``\\ 。现在，这个四边形在世界空间中占据了原点的位置；但是，我们希望它能"
"随着摄像机的移动而移动，这样它就能始终覆盖整个屏幕。为此，我们将绕过坐标转"
"换，该转换通过不同的坐标空间转换顶点位置，并将顶点视为已位于裁剪空间中。"

msgid ""
"The vertex shader expects coordinates to be output in clip space, which are "
"coordinates ranging from ``-1`` at the left and bottom of the screen to "
"``1`` at the top and right of the screen. This is why the QuadMesh needs to "
"have height and width of ``2``. Godot handles the transform from model to "
"view space to clip space behind the scenes, so we need to nullify the "
"effects of Godot's transformations. We do this by setting the ``POSITION`` "
"built-in to our desired position. ``POSITION`` bypasses the built-in "
"transformations and sets the vertex position directly."
msgstr ""
"顶点着色器希望在裁剪空间中输出坐标，即从屏幕左侧和底部的 ``-1`` 到屏幕顶部和"
"右侧的 ``1`` 的坐标。这就是为什么 QuadMesh 的高度和宽度需要是 ``2``\\ 。"
"Godot 会在幕后处理从模型到视图空间再到剪辑空间的转换，所以我们需要使 Godot 的"
"转换效果无效。我们通过设置内置 ``POSITION`` 到我们想要的坐标来做到这一点。\\ "
"``POSITION`` 会绕过内置变换，直接设置顶点坐标。"

msgid ""
"Even with this vertex shader, the quad keeps disappearing. This is due to "
"frustum culling, which is done on the CPU. Frustum culling uses the camera "
"matrix and the AABBs of Meshes to determine if the Mesh will be visible "
"*before* passing it to the GPU. The CPU has no knowledge of what we are "
"doing with the vertices, so it assumes the coordinates specified refer to "
"world positions, not clip space positions, which results in Godot culling "
"the quad when we turn away from the center of the scene. In order to keep "
"the quad from being culled, there are a few options:"
msgstr ""
"即使有了这样的顶点着色器，这个四边形仍会消失。这是因为视锥剔除的缘故，是在 "
"CPU 上完成的。视锥剔除使用摄像机矩阵和 Mesh 的 AABB 来确定 Mesh 是否可见，然"
"后再传递给 GPU。CPU 不知道我们对顶点做了什么，所以它认为指定的坐标指的是世界"
"坐标，而不是裁剪空间的坐标，这就导致了 Godot 在我们旋转、离开场景中心时对四边"
"形进行剔除。为了防止四边形被剔除，有这么几个选项："

msgid ""
"Add the QuadMesh as a child to the camera, so the camera is always pointed "
"at it"
msgstr "将 QuadMesh 作为子节点添加到相机，这样相机就会始终指向它"

msgid ""
"Set the Geometry property ``extra_cull_margin`` as large as possible in the "
"QuadMesh"
msgstr "在 QuadMesh 中将几何属性 ``extra_cull_margin`` 设置得尽可能大"

msgid ""
"The second option ensures that the quad is visible in the editor, while the "
"first option guarantees that it will still be visible even if the camera "
"moves outside the cull margin. You can also use both options."
msgstr ""
"第二个选项会确保四边形在编辑器中可见，而第一个选项能够保证即使摄像机移出剔除"
"边缘也它仍可见。你也可以同时使用这两个选项。"

msgid "Depth texture"
msgstr "深度纹理"

msgid ""
"To read from the depth texture, we first need to create a texture uniform "
"set to the depth buffer by using ``hint_depth_texture``."
msgstr ""

msgid ""
"Once defined, the depth texture can be read with the ``texture()`` function."
msgstr ""

msgid ""
"Similar to accessing the screen texture, accessing the depth texture is only "
"possible when reading from the current viewport. The depth texture cannot be "
"accessed from another viewport to which you have rendered."
msgstr ""
"与访问屏幕纹理类似，访问深度纹理只有在从当前视口读取时才能进行。深度纹理不能"
"从你已经渲染的另一个视口中访问。"

#, fuzzy
msgid ""
"The values returned by ``depth_texture`` are between ``0.0`` and ``1.0`` and "
"are nonlinear. When displaying depth directly from the ``depth_texture``, "
"everything will look almost white unless it is very close. This is because "
"the depth buffer stores objects closer to the camera using more bits than "
"those further, so most of the detail in depth buffer is found close to the "
"camera. In order to make the depth value align with world or model "
"coordinates, we need to linearize the value. When we apply the projection "
"matrix to the vertex position, the z value is made nonlinear, so to "
"linearize it, we multiply it by the inverse of the projection matrix, which "
"in Godot, is accessible with the variable ``INV_PROJECTION_MATRIX``."
msgstr ""
"``DEPTH_TEXTURE`` 返回的值介于 ``0`` 和 ``1`` 之间，并且是非线性的。当直接从 "
"``DEPTH_TEXTURE`` 显示深度时，除非非常接近，否则一切都会看起来几乎是白色的。"
"这是因为深度缓冲区会使用更多的位来存储更靠近相机的对象，因此深度缓冲区中的大"
"部分细节都靠近相机。为了使深度值与世界或模型坐标对齐，我们需要将值线性化，当"
"我们将投影矩阵应用于顶点位置时，Z 值是非线性的，所以为了将其线性化，我们将它"
"乘以投影矩阵的逆矩阵，在 Godot 中可以用变量 ``INV_PROJECTION_MATRIX`` 访问。"

#, fuzzy
msgid ""
"Firstly, take the screen space coordinates and transform them into "
"normalized device coordinates (NDC). NDC run ``-1.0`` to ``1.0`` in ``x`` "
"and ``y`` directions and from ``0.0`` to ``1.0`` in the ``z`` direction when "
"using the Vulkan backend. Reconstruct the NDC using ``SCREEN_UV`` for the "
"``x`` and ``y`` axis, and the depth value for ``z``."
msgstr ""
"首先, 取屏幕空间坐标并将其转换为归一化设备坐标(NDC).NDC从 ``-1`` 到 ``1`` , "
"类似于裁剪空间坐标. 使用 ``SCREEN_UV`` 来重建NDC的 ``x`` 和 ``y`` 轴, 以及 "
"``z`` 的深度值."

msgid ""
"This tutorial assumes the use of the Vulkan renderer, which uses NDCs with a "
"Z-range of ``[0.0, 1.0]``. In contrast, OpenGL uses NDCs with a Z-range of "
"``[-1.0, 1.0]``."
msgstr ""

msgid ""
"Convert NDC to view space by multiplying the NDC by "
"``INV_PROJECTION_MATRIX``. Recall that view space gives positions relative "
"to the camera, so the ``z`` value will give us the distance to the point."
msgstr ""
"通过将NDC乘以 ``INV_PROJECTION_MATRIX`` , 将NDC转换成视图空间. 回顾一下, 视图"
"空间给出了相对于相机的位置, 所以 ``z`` 值将给我们提供到该点的距离."

msgid ""
"Because the camera is facing the negative ``z`` direction, the position will "
"have a negative ``z`` value. In order to get a usable depth value, we have "
"to negate ``view.z``."
msgstr ""
"因为摄像机是朝向负的 ``z`` 方向的, 所以坐标会有一个负的 ``z`` 值. 为了得到一"
"个可用的深度值, 我们必须否定 ``view.z`` ."

#, fuzzy
msgid ""
"The world position can be constructed from the depth buffer using the "
"following code. Note that the ``INV_VIEW_MATRIX`` is needed to transform the "
"position from view space into world space, so it needs to be passed to the "
"fragment shader with a varying."
msgstr ""
"世界坐标可以通过以下代码从深度缓冲区构建. 注意 ``CAMERA_MATRIX`` 需要将坐标从"
"视图空间转换到世界空间, 所以它需要以varying的方式传递给片段着色器."

msgid "An optimization"
msgstr "优化"

msgid ""
"You can benefit from using a single large triangle rather than using a full "
"screen quad. The reason for this is explained `here <https://michaldrobot."
"com/2014/04/01/gcn-execution-patterns-in-full-screen-passes>`_. However, the "
"benefit is quite small and only beneficial when running especially complex "
"fragment shaders."
msgstr ""
"你可以使用单个大三角形而不是使用全屏四边形. 解释的原因在 `这里 <https://"
"michaldrobot.com/2014/04/01/gcn-execution-patterns-in-full-screen-"
"passes>`_ . 但是, 这种好处非常小, 只有在运行特别复杂的片段着色器时才有用."

#, fuzzy
msgid ""
"Set the Mesh in the MeshInstance3D to an :ref:`ArrayMesh <class_ArrayMesh>`. "
"An ArrayMesh is a tool that allows you to easily construct a Mesh from "
"Arrays for vertices, normals, colors, etc."
msgstr ""
"将MeshInstance中的Mesh设置为 :ref:`ArrayMesh <class_ArrayMesh>`. ArrayMesh是"
"一个工具, 允许您从顶点, 法线, 颜色等方便地从数组构造网格."

#, fuzzy
msgid "Now, attach a script to the MeshInstance3D and use the following code:"
msgstr "现在, 将脚本附加到MeshInstance并使用以下代码:"

#, fuzzy
msgid ""
"The triangle is specified in normalized device coordinates. Recall, NDC run "
"from ``-1.0`` to ``1.0`` in both the ``x`` and ``y`` directions. This makes "
"the screen ``2`` units wide and ``2`` units tall. In order to cover the "
"entire screen with a single triangle, use a triangle that is ``4`` units "
"wide and ``4`` units tall, double its height and width."
msgstr ""
"三角形在标准化设备坐标中指定. 回想一下,NDC在 ``x`` 和 ``y`` 方向都从 ``-1`` "
"到 ``1`` 运行. 这使得屏幕 ``2`` 单位宽, ``2`` 单位高. 为了用一个三角形覆盖整"
"个屏幕, 使用一个 ``4`` 单位宽和 ``4`` 单位高的三角形, 高度和宽度加倍."

msgid ""
"Assign the same vertex shader from above and everything should look exactly "
"the same."
msgstr "从上面分配相同的顶点着色器, 所有内容应该看起来完全相同."

#, fuzzy
msgid ""
"The one drawback to using an ArrayMesh over using a QuadMesh is that the "
"ArrayMesh is not visible in the editor because the triangle is not "
"constructed until the scene is run. To get around that, construct a single "
"triangle Mesh in a modeling program and use that in the MeshInstance3D "
"instead."
msgstr ""
"使用ArrayMesh而不是使用QuadMesh的一个缺点是ArrayMesh在编辑器中不可见, 因为在"
"运行场景之前不会构造三角形. 为了解决这个问题, 在建模程序中构建一个三角形"
"Mesh, 然后在MeshInstance中使用它."

msgid "Translation status"
msgstr "翻译状态"
